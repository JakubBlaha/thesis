{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DatasetBuilder, LabelingScheme, DaspsLabeling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import contextlib\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "from models.cnn import EEGNet\n",
    "from models.lstm import EEG_LSTMClassifier\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "def compile_model(\n",
    "        model, learning_rate=0.001, class_weights=None, l1_lambda=0.0):\n",
    "    if class_weights is not None:\n",
    "        class_weights = torch.tensor(\n",
    "            class_weights, dtype=torch.float).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    return criterion, optimizer\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    losses_ = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            scores = model.forward(data)\n",
    "            loss = criterion(scores, targets)\n",
    "            losses_.append(loss.detach())\n",
    "            _, predictions = scores.max(1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    avg_loss = torch.stack(losses_).mean().item()\n",
    "\n",
    "    # Calculate accuracy per label\n",
    "    label_accuracies = {}\n",
    "    for label in set(all_targets):\n",
    "        label_indices = [i for i, target in enumerate(\n",
    "            all_targets) if target == label]\n",
    "        label_predictions = [all_predictions[i] for i in label_indices]\n",
    "        correct_predictions = sum(\n",
    "            1 for pred in label_predictions if pred == label)\n",
    "        accuracy = correct_predictions / len(\n",
    "            label_predictions) if len(label_predictions) > 0 else 0\n",
    "        label_accuracies[label] = accuracy\n",
    "\n",
    "    return avg_loss, all_predictions, all_targets, label_accuracies\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model, train_dataset, test_dataset, *, max_epochs=100,\n",
    "        learning_rate=0.001, batch_size=32, enable_profiling=False, patience=5,\n",
    "        min_epochs=30, class_weights=None, l1_lambda=0.0):\n",
    "    print(\"Train samples: \", len(train_dataset))\n",
    "    print(\"Test samples: \", len(test_dataset))\n",
    "\n",
    "    criterion, optimizer = compile_model(model, learning_rate, class_weights)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    if enable_profiling:\n",
    "        profiler_context = profile(\n",
    "            activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "            record_shapes=True)\n",
    "    else:\n",
    "        profiler_context = contextlib.nullcontext()\n",
    "\n",
    "    epochs_no_improve = 0\n",
    "    best_state_dict = None\n",
    "\n",
    "    best_val_loss = float('inf')  # Initialize with a very high value\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    with profiler_context as prof:\n",
    "        for epoch in tqdm(range(max_epochs)):\n",
    "            model.train()\n",
    "\n",
    "            num_correct = 0\n",
    "            num_samples = 0\n",
    "\n",
    "            losses_ = []\n",
    "\n",
    "            for data, targets in train_loader:\n",
    "                with record_function(\"model_inference\"):\n",
    "                    scores = model.forward(data)\n",
    "                loss = criterion(scores, targets)\n",
    "\n",
    "                # L1 regularization\n",
    "                l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "                loss = loss + l1_lambda * l1_norm\n",
    "\n",
    "                losses_.append(loss.detach())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                _, predictions = scores.max(1)\n",
    "                num_correct += (predictions == targets).sum()\n",
    "                num_samples += predictions.size(0)\n",
    "\n",
    "            train_losses.append(torch.stack(losses_).mean().item())\n",
    "            train_acc.append(num_correct/num_samples)\n",
    "\n",
    "            # Evaluate\n",
    "            val_loss, all_predictions, all_targets, _ = evaluate_model(\n",
    "                model, test_loader, criterion)\n",
    "            val_losses.append(val_loss)\n",
    "            test_acc.append(\n",
    "                np.mean(np.array(all_predictions) == np.array(all_targets)))\n",
    "\n",
    "            current_val_accuracy = test_acc[-1]\n",
    "\n",
    "            if current_val_accuracy > best_val_acc and epoch >= min_epochs:\n",
    "                best_val_acc = current_val_accuracy\n",
    "                epochs_no_improve = 0\n",
    "\n",
    "                # Save model state\n",
    "                best_state_dict = model.state_dict()\n",
    "\n",
    "                for k, v in best_state_dict.items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        best_state_dict[k] = v.cpu()\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= patience and epoch >= min_epochs:\n",
    "                    print(\"Early stopping triggered!\")\n",
    "                    break\n",
    "\n",
    "    if enable_profiling:\n",
    "        print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "    train_acc = [float(i) for i in train_acc]\n",
    "    test_acc = [float(i) for i in test_acc]\n",
    "\n",
    "    plot_training_results(train_losses, val_losses, train_acc, test_acc)\n",
    "\n",
    "    # Load the best model\n",
    "    if best_state_dict is not None:\n",
    "        model.load_state_dict(best_state_dict)\n",
    "\n",
    "    return evaluate_model(model, test_loader, nn.CrossEntropyLoss()), test_acc\n",
    "\n",
    "\n",
    "def seed():\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "\n",
    "def setup_device():\n",
    "    global device\n",
    "\n",
    "    if torch.backends.mps.is_available() and use_gpu:\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available() and use_gpu:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "def plot_training_results(train_losses, val_losses, train_acc, test_acc):\n",
    "    # Plotting with seaborn\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "    configs = [\n",
    "        (axs[0], {\"Train Loss\": train_losses, \"Validation Loss\": val_losses}, \"Loss\"),\n",
    "        (axs[1], {\"Train Accuracy\": train_acc, \"Test Accuracy\": test_acc}, \"Accuracy\")\n",
    "    ]\n",
    "    for index, (ax, data_dict, title) in enumerate(configs):\n",
    "        for label, values in data_dict.items():\n",
    "            sns.lineplot(x=range(len(values)), y=values, ax=ax, label=label)\n",
    "\n",
    "        if index == 1:\n",
    "            ax.set(ylim=(0, 1))\n",
    "\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel(title)\n",
    "        ax.set_xlabel(\"Epochs\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Global variables for parameters\n",
    "mode = \"both\"\n",
    "\n",
    "# Model type selection\n",
    "model_type = \"lstm\"  # Options: \"cnn\" or \"lstm\"\n",
    "\n",
    "# Model-specific configurations\n",
    "model_configs = {\n",
    "    \"cnn\": {\n",
    "        \"learning_rate\": 0.000005,\n",
    "        \"batch_size\": 16,\n",
    "        \"dropout\": 0.4,\n",
    "        \"class_weights\": None,  # [1, 1, 1.3, 1]\n",
    "        \"l1_lambda\": 0.0000,\n",
    "        \"min_epochs\": 12,\n",
    "        \"max_epochs\": 13\n",
    "    },\n",
    "    \"lstm\": {\n",
    "        \"learning_rate\": 0.0005,\n",
    "        \"batch_size\": 32,\n",
    "        \"dropout\": 0,\n",
    "        \"class_weights\": None,\n",
    "        \"l1_lambda\": 0.0000,\n",
    "        \"min_epochs\": 15,\n",
    "        \"max_epochs\": 50\n",
    "    }\n",
    "}\n",
    "\n",
    "seglen = 30\n",
    "merge_control = True\n",
    "oversample = True\n",
    "\n",
    "device = None\n",
    "use_gpu = True\n",
    "\n",
    "all_subj_ids = [\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
    "    22, 23, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
    "    114, 115, 116, 117, 118, 119, 120, 121, 401, 402, 403, 404, 405, 406, 407,\n",
    "    408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421]\n",
    "\n",
    "random.seed(42)\n",
    "shuffled_ids = all_subj_ids.copy()\n",
    "random.shuffle(shuffled_ids)\n",
    "\n",
    "n_in_split = 5\n",
    "val_splits = [\n",
    "    shuffled_ids[i: i + n_in_split]\n",
    "    for i in range(0, len(shuffled_ids),\n",
    "                   n_in_split)]\n",
    "\n",
    "# classes = [\n",
    "#     [10, 14, 8, 9, 15, 18, 23],\n",
    "#     [11, 13, 21, 1, 2, 3, 4, 5, 6, 7, 12, 16, 17, 19, 20, 22],\n",
    "# ]\n",
    "\n",
    "# val_splits = [[i] for i in all_subj_ids]\n",
    "\n",
    "\n",
    "def leave_subjects_out_cv(\n",
    "        *, test_subj_ids, labeling_scheme,\n",
    "        dataset_builder: DatasetBuilder):\n",
    "    print(\"Test subjects: \", test_subj_ids)\n",
    "\n",
    "    # Get current model config\n",
    "    config = model_configs[model_type]\n",
    "\n",
    "    train, test = dataset_builder.build_deep_datasets_train_test(\n",
    "        insert_ch_dim=False, test_subj_ids=test_subj_ids, device=device)\n",
    "\n",
    "    if len(test) == 0:\n",
    "        return None\n",
    "\n",
    "    num_classes = len(builder.last_int_to_label.keys())\n",
    "\n",
    "    # Select model based on model_type\n",
    "    if model_type == \"cnn\":\n",
    "        model = EEGNet(num_classes=num_classes, dropout=config[\"dropout\"])\n",
    "    elif model_type == \"lstm\":\n",
    "        model = EEG_LSTMClassifier(input_size=14, num_classes=num_classes,\n",
    "                                   dropout=config[\"dropout\"],\n",
    "                                   hidden_sizes=[45, 30],\n",
    "                                   bidirectional=False,\n",
    "                                   use_attention=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    return train_model(\n",
    "        model, train, test,\n",
    "        max_epochs=config[\"max_epochs\"],\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        enable_profiling=False,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        min_epochs=config[\"min_epochs\"],\n",
    "        class_weights=config[\"class_weights\"],\n",
    "        l1_lambda=config[\"l1_lambda\"])\n",
    "\n",
    "\n",
    "def gen_conf_matrix(all_targets, all_predictions, int_to_label: dict):\n",
    "    conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "    uniq_labels_names = [int_to_label[i] for i in sorted(int_to_label.keys())]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=uniq_labels_names, yticklabels=uniq_labels_names)\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    setup_device()\n",
    "\n",
    "    # Build dataset\n",
    "    labeling_scheme = LabelingScheme(\n",
    "        DaspsLabeling.HAM, merge_control=merge_control)\n",
    "    builder = DatasetBuilder(\n",
    "        labeling_scheme, seglen=seglen, mode=mode, oversample=oversample)\n",
    "\n",
    "    test_losses = []\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_accuracies = {}\n",
    "    best_epochs = []\n",
    "    group_test_accuracies = {}\n",
    "\n",
    "    config = model_configs[model_type]  # Get current model config\n",
    "\n",
    "    for test_subjs in val_splits:\n",
    "        seed()\n",
    "\n",
    "        ret = leave_subjects_out_cv(\n",
    "            test_subj_ids=test_subjs,\n",
    "            labeling_scheme=labeling_scheme,\n",
    "            dataset_builder=builder)\n",
    "\n",
    "        if ret is None:\n",
    "            continue\n",
    "\n",
    "        (_test_loss, _all_predictions, _all_targets,\n",
    "         _label_accuracies), _test_accuracies = ret\n",
    "\n",
    "        test_losses.append(_test_loss)\n",
    "        all_predictions.extend(_all_predictions)\n",
    "        all_targets.extend(_all_targets)\n",
    "\n",
    "        for label in set(_label_accuracies.keys()):\n",
    "            if label not in all_accuracies:\n",
    "                all_accuracies[label] = []\n",
    "            all_accuracies[label].append(_label_accuracies[label])\n",
    "\n",
    "        _best_epoch = np.argmax(\n",
    "            _test_accuracies[config[\"min_epochs\"]:]) + config[\"min_epochs\"]\n",
    "        _best_accuracy = _test_accuracies[_best_epoch]\n",
    "\n",
    "        best_epochs.append(_best_epoch)\n",
    "\n",
    "        print(f\"Best epoch: {_best_epoch}\")\n",
    "        print(\"Best accuracy: \", _best_accuracy)\n",
    "        print(\"----------------\")\n",
    "\n",
    "        group_test_accuracies[tuple(test_subjs)] = _best_accuracy\n",
    "\n",
    "    # Statistics\n",
    "    total_test_acc = np.mean(np.array(all_predictions)\n",
    "                             == np.array(all_targets))\n",
    "    total_test_loss = np.mean(test_losses)\n",
    "    avg_all_accuracies = {k: np.mean(v) for k, v in all_accuracies.items()}\n",
    "    print(f\"Mean Test Loss: {total_test_loss}\")\n",
    "    print(f\"Mean Test Accuracy: {total_test_acc}\")\n",
    "\n",
    "    # Calculate mean and max of best epochs\n",
    "    mean_best_epoch = np.mean(best_epochs)\n",
    "    max_best_epoch = np.max(best_epochs)\n",
    "    print(f\"Mean Best Epoch: {mean_best_epoch}\")\n",
    "    print(f\"Max Best Epoch: {max_best_epoch}\")\n",
    "\n",
    "    # Conf matrix\n",
    "    gen_conf_matrix(all_targets, all_predictions, builder.last_int_to_label)\n",
    "\n",
    "    # Print label accuracies\n",
    "    all_accuracies_mean = {\n",
    "        builder.last_int_to_label[k]: v for k, v in avg_all_accuracies.items()}\n",
    "    table_acc_mean = tabulate(\n",
    "        all_accuracies_mean.items(),\n",
    "        headers=['Label', 'Mean Accuracy'])\n",
    "    print(table_acc_mean)\n",
    "\n",
    "    # Print test accuracies for each group\n",
    "    print(\"\\nTest Accuracies for Each Group:\")\n",
    "    for group, accuracy in group_test_accuracies.items():\n",
    "        print(f\"Group {group}: {accuracy:.2f}\")\n",
    "\n",
    "    # Print class weights from config\n",
    "    if config[\"class_weights\"] is not None:\n",
    "        print(\"Class weights: \", config[\"class_weights\"])\n",
    "\n",
    "    print(\"Total splits: \", len(val_splits))\n",
    "\n",
    "    print(\"Script execution finished.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
